{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doppelganger_github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbdQhZZD2iqTcWNLopIvHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noo-rashbass/synthetic-data-service/blob/master/doppelganger/gan/doppelganger_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVtrfzbuqc3O"
      },
      "source": [
        "####Choose GPU runtime\n",
        "Select Runtime, \n",
        "\n",
        "change runtime type, \n",
        "\n",
        "Hardware Accelerator-GPU, \n",
        "\n",
        "untick \"Omit cell output...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CgT3jS4ustn"
      },
      "source": [
        "#### To prevent Colab from disconnecting\n",
        "\n",
        "ctrl + shift + I\n",
        "\n",
        "go to Console\n",
        "\n",
        "Paste the following:\n",
        "~~~\n",
        "function KeepClicking(){\n",
        "console.log(\"Clicking\");\n",
        "document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(KeepClicking,60000)\n",
        "~~~\n",
        "or \n",
        "~~~\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button\").click() \n",
        "}setInterval(ClickConnect,60000)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JuWbuk7q39i"
      },
      "source": [
        "####Upload the data files and doppelganger code from Github\n",
        "Your directory should look like this\n",
        "\n",
        "-data  \n",
        "  >--data_attribute_output.pkl  \n",
        "  --data_feature_output.pkl  \n",
        "  --data_train.npz  \n",
        "\n",
        "-doppelganger.py  \n",
        "-load_data.py  \n",
        "-network.py  \n",
        "-networkGenerator.py  \n",
        "-output.py  \n",
        "-util.py\n",
        "\n",
        "Note: You do not need to upload main.py. Example of what the directory should look like with checkpoint folders are at the end of the notebook  \n",
        "\n",
        "To use first_dday as an attribute (separate column), upload files from data_attr folder on Github and put under the data folder on Colab\n",
        "\n",
        "If first_dday is not considered as attribute, upload files from data folder on Github and put under the data folder on Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3lHRPzhV3Eh"
      },
      "source": [
        "### Uploading checkpoints\n",
        "\n",
        "If any checkpoint zip folders were downloaded previously, upload the 3 zip files (xxx.zip) and use the cell below to unzip into their respective folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R57qTrAClRzy",
        "outputId": "aee109a6-0421-4616-9477-a74e69818beb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# unzip data file\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: data_train.npz          \n",
            "  inflating: data_attribute_output.pkl  \n",
            "  inflating: data_feature_output.pkl  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkum1dk3oKvC"
      },
      "source": [
        "!rm -rf data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CMo2rS4VuaY",
        "outputId": "caf00a42-d125-446c-b770-a91a446ba683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!unzip tf_ckpts_ad.zip\n",
        "!unzip tf_ckpts_d.zip\n",
        "!unzip tf_ckpts_g.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  tf_ckpts_ad.zip\n",
            "   creating: tf_ckpts_ad/\n",
            "  inflating: tf_ckpts_ad/ckpt-800.index  \n",
            "  inflating: tf_ckpts_ad/ckpt-799.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_ad/ckpt-798.index  \n",
            "  inflating: tf_ckpts_ad/ckpt-799.index  \n",
            "  inflating: tf_ckpts_ad/checkpoint  \n",
            "  inflating: tf_ckpts_ad/ckpt-800.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_ad/ckpt-798.data-00000-of-00001  \n",
            "Archive:  tf_ckpts_d.zip\n",
            "   creating: tf_ckpts_d/\n",
            "  inflating: tf_ckpts_d/ckpt-800.index  \n",
            "  inflating: tf_ckpts_d/ckpt-799.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_d/ckpt-798.index  \n",
            "  inflating: tf_ckpts_d/ckpt-799.index  \n",
            "  inflating: tf_ckpts_d/checkpoint   \n",
            "  inflating: tf_ckpts_d/ckpt-800.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_d/ckpt-798.data-00000-of-00001  \n",
            "Archive:  tf_ckpts_g.zip\n",
            "   creating: tf_ckpts_g/\n",
            "  inflating: tf_ckpts_g/ckpt-800.index  \n",
            "  inflating: tf_ckpts_g/ckpt-799.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_g/ckpt-798.index  \n",
            "  inflating: tf_ckpts_g/ckpt-799.index  \n",
            "  inflating: tf_ckpts_g/checkpoint   \n",
            "  inflating: tf_ckpts_g/ckpt-800.data-00000-of-00001  \n",
            "  inflating: tf_ckpts_g/ckpt-798.data-00000-of-00001  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhPhIK0uY5L4"
      },
      "source": [
        "# remove zip files you just uploaded\n",
        "!rm -rf tf_ckpts_ad.zip\n",
        "!rm -rf tf_ckpts_d.zip\n",
        "!rm -rf tf_ckpts_g.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2uXWzkEsUdp"
      },
      "source": [
        "####Start training and generating data with DoppelGANger by running the cell below\n",
        "\n",
        "Note: Change epochs, batch_size and cumsum_bool if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Vj1DIDp0kB",
        "outputId": "2bd572de-b585-421d-b38c-b4a2956378b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from load_data import *\n",
        "from util import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from network import make_discriminator, make_attrdiscriminator\n",
        "from networkGenerator import DoppelGANgerGenerator\n",
        "from doppelganger import DoppelGANger\n",
        "\n",
        "## change these values if needed\n",
        "seq_len = 130\n",
        "batch_size = 64\n",
        "epochs = 200\n",
        "total_generate_num_sample = 1347\n",
        "cumsum_bool = True                # change to True to run the code that tries 2 peaks\n",
        "path_to_data = \"data\"\n",
        "\n",
        "(data_feature, data_attribute, data_gen_flag, data_feature_outputs, data_attribute_outputs) = load_data(path_to_data)\n",
        "\n",
        "print(\"-----DATA LOADING-----\")\n",
        "print(data_feature.shape)          # original features_dim        \n",
        "print(data_attribute.shape)        # original attributes_dim\n",
        "print(data_gen_flag.shape)\n",
        "num_real_attribute = len(data_attribute_outputs)\n",
        "\n",
        "(data_feature, data_attribute, data_attribute_outputs, real_attribute_mask) = \\\n",
        "    normalize_per_sample(data_feature, data_attribute, data_feature_outputs,data_attribute_outputs)\n",
        "\n",
        "print(\"-----DATA NORMALIZATION-----\")\n",
        "print(real_attribute_mask)\n",
        "print(data_feature.shape)\n",
        "attributes_dim = data_attribute.shape[1]    # attributes_dim to be fed into model\n",
        "print(data_attribute.shape)       \n",
        "print(len(data_attribute_outputs))\n",
        "\n",
        "print(\"-----ADD GEN FLAG -----\")\n",
        "data_feature, data_feature_outputs = add_gen_flag(\n",
        "        data_feature, data_gen_flag, data_feature_outputs, seq_len)\n",
        "features_dim = data_feature.shape[2]    # features dim to be fed into model\n",
        "print(data_feature.shape)        \n",
        "print(len(data_feature_outputs))\n",
        "\n",
        "discriminator_model = make_discriminator(seq_len, features_dim, attributes_dim)\n",
        "attrdiscriminator_model = make_attrdiscriminator(attributes_dim)\n",
        "\n",
        "generator = DoppelGANgerGenerator(\n",
        "        feed_back=False,\n",
        "        noise=True,\n",
        "        feature_outputs=data_feature_outputs,\n",
        "        attribute_outputs=data_attribute_outputs,\n",
        "        real_attribute_mask=real_attribute_mask,\n",
        "        sample_len=seq_len)\n",
        "\n",
        "\n",
        "gan = DoppelGANger(\n",
        "    epoch=epochs, \n",
        "    batch_size=batch_size, \n",
        "    data_feature=data_feature, \n",
        "    data_attribute=data_attribute, \n",
        "    real_attribute_mask=real_attribute_mask, \n",
        "    data_gen_flag=data_gen_flag,\n",
        "    seq_len=seq_len, \n",
        "    data_feature_outputs=data_feature_outputs, \n",
        "    data_attribute_outputs=data_feature_outputs,\n",
        "    generator = generator, \n",
        "    discriminator = discriminator_model, \n",
        "    d_rounds=1, \n",
        "    g_rounds=1, \n",
        "    d_gp_coe=10.,\n",
        "    num_packing=1,\n",
        "    attr_discriminator=attrdiscriminator_model,\n",
        "    attr_d_gp_coe=10., \n",
        "    g_attr_d_coe=1.0,\n",
        "    cumsum=cumsum_bool)\n",
        "\n",
        "#combine data attributes and features into one to be fed into the model\n",
        "# data_attribute_in = tf.expand_dims(data_attribute, axis=1)\n",
        "# data_attribute_in = tf.repeat(data_attribute_in, repeats=seq_len, axis=1)\n",
        "# data_all_in = tf.cast(tf.concat([data_feature, data_attribute_in], axis=2), dtype=tf.float32)\n",
        "\n",
        "print(\"----START TRAINING-----\")\n",
        "#gan.compile()\n",
        "\n",
        "# if any callbacks are needed\n",
        "# callback1 = tf.keras.callbacks.EarlyStopping(monitor='d_loss', patience=3)\n",
        "# callback2 = tf.keras.callbacks.EarlyStopping(monitor='ad_loss', patience=3)\n",
        "# callback3 = tf.keras.callbacks.EarlyStopping(monitor='g_loss', patience=3)\n",
        "\n",
        "#gan.fit(data_all_in, batch_size=batch_size, epochs=epochs) #, callbacks=[callback1, callback2]\n",
        "gan.train_step()\n",
        "\n",
        "print(\"----FINISHED TRAINING-----\")\n",
        "\n",
        "print(\"----START GENERATING------\")\n",
        "\n",
        "if data_feature.shape[1] % seq_len != 0:\n",
        "    raise Exception(\"length must be a multiple of sample_len\")\n",
        "length = int(data_feature.shape[1] / seq_len)\n",
        "real_attribute_input_noise = gan.gen_attribute_input_noise(total_generate_num_sample) #(?,5)\n",
        "addi_attribute_input_noise = gan.gen_attribute_input_noise(total_generate_num_sample) #(?,5)\n",
        "feature_input_noise = gan.gen_feature_input_noise(total_generate_num_sample, length) #(?,1,5)\n",
        "input_data = gan.gen_feature_input_data_free(total_generate_num_sample) #(?,28)\n",
        "\n",
        "features, attributes, gen_flags, lengths = \\\n",
        "    gan.sample_from(real_attribute_input_noise, addi_attribute_input_noise,feature_input_noise, input_data)\n",
        "# specify given_attribute parameter, if you want to generate\n",
        "# data according to an attribute\n",
        "print(\"----SAMPLE FROM-----\")\n",
        "print(features.shape)\n",
        "print(attributes.shape)\n",
        "print(gen_flags.shape)\n",
        "print(lengths.shape)\n",
        "\n",
        "features, attributes = renormalize_per_sample(features, attributes, data_feature_outputs,\n",
        "    data_attribute_outputs, gen_flags, num_real_attribute=num_real_attribute)\n",
        "print(\"----RENORMALIZATION-----\")\n",
        "print(features.shape)\n",
        "print(attributes.shape)\n",
        "\n",
        "np.savez(\n",
        "        \"generated_data_train.npz\",\n",
        "        data_feature=features,\n",
        "        data_attribute=attributes,\n",
        "        data_gen_flag=gen_flags)\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----DATA LOADING-----\n",
            "(1347, 130, 47)\n",
            "(1347, 1)\n",
            "(1347, 130)\n",
            "-----DATA NORMALIZATION-----\n",
            "[True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "(1347, 130, 47)\n",
            "(1347, 35)\n",
            "35\n",
            "-----ADD GEN FLAG -----\n",
            "(1347, 130, 49)\n",
            "27\n",
            "----START TRAINING-----\n",
            "G restored from tf_ckpts_g/ckpt-800\n",
            "D restored from tf_ckpts_d/ckpt-800\n",
            "AD restored from tf_ckpts_ad/ckpt-800\n",
            "epoch:  0\n",
            "WARNING:tensorflow:Layer doppel_ga_nger_generator is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Layer dense_3523 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Layer doppel_ga_nger_generator_rnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "d_loss:  -25.303852 , ad_loss:  -0.008108425 , g_loss:  25.283855\n",
            "epoch:  1\n",
            "d_loss:  -25.195637 , ad_loss:  -0.0088933 , g_loss:  25.370611\n",
            "epoch:  2\n",
            "d_loss:  -26.057713 , ad_loss:  -0.010880368 , g_loss:  26.017504\n",
            "epoch:  3\n",
            "d_loss:  -24.660706 , ad_loss:  -0.018150529 , g_loss:  26.303926\n",
            "epoch:  4\n",
            "d_loss:  -25.232374 , ad_loss:  -0.009871561 , g_loss:  25.902956\n",
            "epoch:  5\n",
            "d_loss:  -24.443216 , ad_loss:  0.0120238485 , g_loss:  25.287453\n",
            "epoch:  6\n",
            "d_loss:  -24.836876 , ad_loss:  -0.011531454 , g_loss:  25.18152\n",
            "epoch:  7\n",
            "d_loss:  -24.3379 , ad_loss:  0.027392322 , g_loss:  25.451422\n",
            "epoch:  8\n",
            "d_loss:  -24.716858 , ad_loss:  0.008151733 , g_loss:  26.330006\n",
            "epoch:  9\n",
            "d_loss:  -24.515835 , ad_loss:  0.0002837833 , g_loss:  25.458084\n",
            "epoch:  10\n",
            "d_loss:  -25.107876 , ad_loss:  -0.0034948448 , g_loss:  25.402424\n",
            "epoch:  11\n",
            "d_loss:  -24.320698 , ad_loss:  0.0023522293 , g_loss:  25.563078\n",
            "epoch:  12\n",
            "d_loss:  -25.055918 , ad_loss:  0.018274143 , g_loss:  25.478855\n",
            "epoch:  13\n",
            "d_loss:  -24.576393 , ad_loss:  -0.011011963 , g_loss:  26.166218\n",
            "epoch:  14\n",
            "d_loss:  -25.224293 , ad_loss:  0.0304805 , g_loss:  26.560112\n",
            "epoch:  15\n",
            "d_loss:  -23.933447 , ad_loss:  0.0040780734 , g_loss:  25.674015\n",
            "epoch:  16\n",
            "d_loss:  -25.159622 , ad_loss:  0.002095718 , g_loss:  25.081562\n",
            "epoch:  17\n",
            "d_loss:  -25.213932 , ad_loss:  0.01760577 , g_loss:  26.20586\n",
            "epoch:  18\n",
            "d_loss:  -26.186855 , ad_loss:  -0.01618816 , g_loss:  25.76733\n",
            "epoch:  19\n",
            "d_loss:  -24.785742 , ad_loss:  -0.0042146333 , g_loss:  25.315792\n",
            "epoch:  20\n",
            "d_loss:  -25.726292 , ad_loss:  0.0057608653 , g_loss:  26.386055\n",
            "epoch:  21\n",
            "d_loss:  -24.337208 , ad_loss:  -0.011355968 , g_loss:  27.141876\n",
            "epoch:  22\n",
            "d_loss:  -25.937078 , ad_loss:  0.004466772 , g_loss:  26.770855\n",
            "epoch:  23\n",
            "d_loss:  -24.63562 , ad_loss:  -0.0039541805 , g_loss:  25.956987\n",
            "epoch:  24\n",
            "d_loss:  -23.679253 , ad_loss:  -0.0029335222 , g_loss:  25.839571\n",
            "epoch:  25\n",
            "d_loss:  -25.274147 , ad_loss:  0.007839101 , g_loss:  27.688168\n",
            "epoch:  26\n",
            "d_loss:  -24.226976 , ad_loss:  -0.0011945143 , g_loss:  26.984762\n",
            "epoch:  27\n",
            "d_loss:  -25.204079 , ad_loss:  0.00783276 , g_loss:  26.185688\n",
            "epoch:  28\n",
            "d_loss:  -24.507229 , ad_loss:  0.016162815 , g_loss:  26.359688\n",
            "epoch:  29\n",
            "d_loss:  -25.175993 , ad_loss:  -0.00034076162 , g_loss:  27.831518\n",
            "epoch:  30\n",
            "d_loss:  -25.481728 , ad_loss:  0.0047171065 , g_loss:  27.017673\n",
            "epoch:  31\n",
            "d_loss:  -24.392584 , ad_loss:  -0.024693437 , g_loss:  26.779243\n",
            "epoch:  32\n",
            "d_loss:  -24.9977 , ad_loss:  -0.027138678 , g_loss:  27.49154\n",
            "epoch:  33\n",
            "d_loss:  -24.383816 , ad_loss:  -0.029808406 , g_loss:  26.85595\n",
            "epoch:  34\n",
            "d_loss:  -24.928875 , ad_loss:  0.014291178 , g_loss:  27.551691\n",
            "epoch:  35\n",
            "d_loss:  -24.182373 , ad_loss:  0.0073685776 , g_loss:  27.953505\n",
            "epoch:  36\n",
            "d_loss:  -24.256023 , ad_loss:  -0.01529937 , g_loss:  27.988625\n",
            "epoch:  37\n",
            "d_loss:  -24.819256 , ad_loss:  -0.008909212 , g_loss:  27.228521\n",
            "epoch:  38\n",
            "d_loss:  -25.497776 , ad_loss:  0.0069465456 , g_loss:  28.535631\n",
            "epoch:  39\n",
            "d_loss:  -23.930614 , ad_loss:  -0.0032006819 , g_loss:  26.76548\n",
            "epoch:  40\n",
            "d_loss:  -25.094248 , ad_loss:  -0.028156646 , g_loss:  28.02442\n",
            "epoch:  41\n",
            "d_loss:  -25.469822 , ad_loss:  -0.016994117 , g_loss:  26.507215\n",
            "epoch:  42\n",
            "d_loss:  -25.06936 , ad_loss:  0.0083372565 , g_loss:  27.555023\n",
            "epoch:  43\n",
            "d_loss:  -24.26139 , ad_loss:  -0.021876566 , g_loss:  27.211359\n",
            "epoch:  44\n",
            "d_loss:  -24.695198 , ad_loss:  0.006919738 , g_loss:  27.826982\n",
            "epoch:  45\n",
            "d_loss:  -24.561367 , ad_loss:  0.24189825 , g_loss:  27.235477\n",
            "epoch:  46\n",
            "d_loss:  -24.737022 , ad_loss:  -0.008350996 , g_loss:  27.79022\n",
            "epoch:  47\n",
            "d_loss:  -25.544905 , ad_loss:  0.002852831 , g_loss:  27.976448\n",
            "epoch:  48\n",
            "d_loss:  -24.697723 , ad_loss:  0.00086144987 , g_loss:  27.18808\n",
            "epoch:  49\n",
            "d_loss:  -24.985655 , ad_loss:  -0.013372609 , g_loss:  26.905542\n",
            "epoch:  50\n",
            "d_loss:  -25.492031 , ad_loss:  -0.029503958 , g_loss:  27.16402\n",
            "epoch:  51\n",
            "d_loss:  -25.219925 , ad_loss:  -0.005156389 , g_loss:  26.907757\n",
            "epoch:  52\n",
            "d_loss:  -25.214535 , ad_loss:  -3.6372046e-05 , g_loss:  27.251968\n",
            "epoch:  53\n",
            "d_loss:  -23.786 , ad_loss:  0.030150037 , g_loss:  26.574097\n",
            "epoch:  54\n",
            "d_loss:  -24.002434 , ad_loss:  -0.0051563554 , g_loss:  25.736465\n",
            "epoch:  55\n",
            "d_loss:  -24.859543 , ad_loss:  0.0059529976 , g_loss:  27.102552\n",
            "epoch:  56\n",
            "d_loss:  -24.314663 , ad_loss:  0.013290367 , g_loss:  27.358372\n",
            "epoch:  57\n",
            "d_loss:  -24.575466 , ad_loss:  -0.010501907 , g_loss:  26.846035\n",
            "epoch:  58\n",
            "d_loss:  -24.456549 , ad_loss:  0.008048048 , g_loss:  26.83875\n",
            "epoch:  59\n",
            "d_loss:  -25.044893 , ad_loss:  0.0121272635 , g_loss:  27.975056\n",
            "epoch:  60\n",
            "d_loss:  -23.843792 , ad_loss:  0.010736767 , g_loss:  26.321009\n",
            "epoch:  61\n",
            "d_loss:  -24.41457 , ad_loss:  -0.0075768046 , g_loss:  26.914158\n",
            "epoch:  62\n",
            "d_loss:  -26.449688 , ad_loss:  -0.0088943485 , g_loss:  27.377716\n",
            "epoch:  63\n",
            "d_loss:  -24.760902 , ad_loss:  0.092313424 , g_loss:  27.452301\n",
            "epoch:  64\n",
            "d_loss:  -24.011168 , ad_loss:  0.017852886 , g_loss:  26.99267\n",
            "epoch:  65\n",
            "d_loss:  -25.230366 , ad_loss:  0.0068152547 , g_loss:  26.262758\n",
            "epoch:  66\n",
            "d_loss:  -24.3925 , ad_loss:  0.0032823302 , g_loss:  28.208132\n",
            "epoch:  67\n",
            "d_loss:  -25.33638 , ad_loss:  -0.006023492 , g_loss:  27.094002\n",
            "epoch:  68\n",
            "d_loss:  -25.748177 , ad_loss:  0.0010728529 , g_loss:  26.935959\n",
            "epoch:  69\n",
            "d_loss:  -24.851673 , ad_loss:  -0.027294239 , g_loss:  28.642004\n",
            "epoch:  70\n",
            "d_loss:  -24.155972 , ad_loss:  -0.010705137 , g_loss:  27.132013\n",
            "epoch:  71\n",
            "d_loss:  -26.069345 , ad_loss:  0.010817636 , g_loss:  26.563158\n",
            "epoch:  72\n",
            "d_loss:  -25.270052 , ad_loss:  0.021367814 , g_loss:  26.4999\n",
            "epoch:  73\n",
            "d_loss:  -25.429253 , ad_loss:  -0.007940028 , g_loss:  26.388342\n",
            "epoch:  74\n",
            "d_loss:  -24.340416 , ad_loss:  -0.003289386 , g_loss:  26.609367\n",
            "epoch:  75\n",
            "d_loss:  -25.650845 , ad_loss:  -0.0165676 , g_loss:  27.975355\n",
            "epoch:  76\n",
            "d_loss:  -25.854504 , ad_loss:  -0.02014168 , g_loss:  27.09483\n",
            "epoch:  77\n",
            "d_loss:  -25.466362 , ad_loss:  -0.013112685 , g_loss:  25.742407\n",
            "epoch:  78\n",
            "d_loss:  -23.578169 , ad_loss:  -0.009866817 , g_loss:  27.307272\n",
            "epoch:  79\n",
            "d_loss:  -24.940958 , ad_loss:  -0.02937671 , g_loss:  26.287111\n",
            "epoch:  80\n",
            "d_loss:  -25.854456 , ad_loss:  -0.019919943 , g_loss:  28.033138\n",
            "epoch:  81\n",
            "d_loss:  -24.682056 , ad_loss:  -0.012109289 , g_loss:  27.424389\n",
            "epoch:  82\n",
            "d_loss:  -26.506561 , ad_loss:  -0.0018368152 , g_loss:  27.331465\n",
            "epoch:  83\n",
            "d_loss:  -24.275091 , ad_loss:  -0.0049337707 , g_loss:  27.064205\n",
            "epoch:  84\n",
            "d_loss:  -25.098269 , ad_loss:  0.039842863 , g_loss:  26.307343\n",
            "epoch:  85\n",
            "d_loss:  -24.896503 , ad_loss:  0.0038493134 , g_loss:  26.745346\n",
            "epoch:  86\n",
            "d_loss:  -24.604715 , ad_loss:  -0.009261172 , g_loss:  26.709549\n",
            "epoch:  87\n",
            "d_loss:  -23.707792 , ad_loss:  -0.02257845 , g_loss:  26.856514\n",
            "epoch:  88\n",
            "d_loss:  -25.346928 , ad_loss:  -0.0024329354 , g_loss:  25.953833\n",
            "epoch:  89\n",
            "d_loss:  -24.5397 , ad_loss:  -0.021933077 , g_loss:  26.92009\n",
            "epoch:  90\n",
            "d_loss:  -24.907846 , ad_loss:  0.0011139151 , g_loss:  27.077625\n",
            "epoch:  91\n",
            "d_loss:  -26.061613 , ad_loss:  -0.0031438991 , g_loss:  27.06663\n",
            "epoch:  92\n",
            "d_loss:  -24.666065 , ad_loss:  0.01975316 , g_loss:  27.499065\n",
            "epoch:  93\n",
            "d_loss:  -25.539198 , ad_loss:  -0.035973694 , g_loss:  26.137383\n",
            "epoch:  94\n",
            "d_loss:  -23.606318 , ad_loss:  -0.0031923673 , g_loss:  25.943838\n",
            "epoch:  95\n",
            "d_loss:  -24.878893 , ad_loss:  -0.011310358 , g_loss:  27.106129\n",
            "epoch:  96\n",
            "d_loss:  -24.72753 , ad_loss:  -0.0002721058 , g_loss:  26.379107\n",
            "epoch:  97\n",
            "d_loss:  -25.405663 , ad_loss:  0.019269995 , g_loss:  26.829206\n",
            "epoch:  98\n",
            "d_loss:  -24.49401 , ad_loss:  0.005350676 , g_loss:  25.525059\n",
            "epoch:  99\n",
            "d_loss:  -25.3647 , ad_loss:  0.05032885 , g_loss:  26.060877\n",
            "epoch:  100\n",
            "d_loss:  -25.136375 , ad_loss:  -0.0093261525 , g_loss:  24.138577\n",
            "epoch:  101\n",
            "d_loss:  -25.294033 , ad_loss:  -0.009104319 , g_loss:  26.810303\n",
            "epoch:  102\n",
            "d_loss:  -24.367046 , ad_loss:  -0.004645249 , g_loss:  26.160076\n",
            "epoch:  103\n",
            "d_loss:  -24.030323 , ad_loss:  0.0018470276 , g_loss:  26.285929\n",
            "epoch:  104\n",
            "d_loss:  -24.918797 , ad_loss:  -0.005252129 , g_loss:  26.239668\n",
            "epoch:  105\n",
            "d_loss:  -25.81392 , ad_loss:  -0.0026836041 , g_loss:  26.66203\n",
            "epoch:  106\n",
            "d_loss:  -24.285109 , ad_loss:  -0.016289985 , g_loss:  25.629208\n",
            "epoch:  107\n",
            "d_loss:  -23.971943 , ad_loss:  -0.011605689 , g_loss:  23.604311\n",
            "epoch:  108\n",
            "d_loss:  -25.508982 , ad_loss:  0.0111375945 , g_loss:  25.769234\n",
            "epoch:  109\n",
            "d_loss:  -24.153225 , ad_loss:  0.003386295 , g_loss:  27.378132\n",
            "epoch:  110\n",
            "d_loss:  -25.37419 , ad_loss:  -0.0021985965 , g_loss:  25.172699\n",
            "epoch:  111\n",
            "d_loss:  -24.485195 , ad_loss:  -0.019711936 , g_loss:  24.909523\n",
            "epoch:  112\n",
            "d_loss:  -25.421926 , ad_loss:  -0.015919829 , g_loss:  24.500637\n",
            "epoch:  113\n",
            "d_loss:  -25.248602 , ad_loss:  -0.006024084 , g_loss:  24.936323\n",
            "epoch:  114\n",
            "d_loss:  -23.715479 , ad_loss:  -0.015341219 , g_loss:  25.822392\n",
            "epoch:  115\n",
            "d_loss:  -25.339813 , ad_loss:  -0.01597116 , g_loss:  25.198833\n",
            "epoch:  116\n",
            "d_loss:  -25.582558 , ad_loss:  -0.002590986 , g_loss:  25.576632\n",
            "epoch:  117\n",
            "d_loss:  -23.627247 , ad_loss:  0.024790302 , g_loss:  25.452736\n",
            "epoch:  118\n",
            "d_loss:  -24.162703 , ad_loss:  -0.018791053 , g_loss:  25.114899\n",
            "epoch:  119\n",
            "d_loss:  -24.977905 , ad_loss:  -0.01442756 , g_loss:  25.1786\n",
            "epoch:  120\n",
            "d_loss:  -24.578686 , ad_loss:  0.009450149 , g_loss:  24.372984\n",
            "epoch:  121\n",
            "d_loss:  -24.313465 , ad_loss:  -0.0037802183 , g_loss:  24.893583\n",
            "epoch:  122\n",
            "d_loss:  -24.767897 , ad_loss:  0.008642938 , g_loss:  26.50861\n",
            "epoch:  123\n",
            "d_loss:  -23.858349 , ad_loss:  0.00851656 , g_loss:  23.618929\n",
            "epoch:  124\n",
            "d_loss:  -24.481112 , ad_loss:  -0.0037887583 , g_loss:  25.046005\n",
            "epoch:  125\n",
            "d_loss:  -24.775288 , ad_loss:  0.01790163 , g_loss:  25.931492\n",
            "epoch:  126\n",
            "d_loss:  -22.721254 , ad_loss:  0.005870672 , g_loss:  23.7857\n",
            "epoch:  127\n",
            "d_loss:  -25.256975 , ad_loss:  -0.010510122 , g_loss:  25.1922\n",
            "epoch:  128\n",
            "d_loss:  -25.754173 , ad_loss:  -0.0034216382 , g_loss:  25.175566\n",
            "epoch:  129\n",
            "d_loss:  -23.688915 , ad_loss:  0.009595174 , g_loss:  25.223492\n",
            "epoch:  130\n",
            "d_loss:  -24.68367 , ad_loss:  -0.002303426 , g_loss:  24.66103\n",
            "epoch:  131\n",
            "d_loss:  -24.794254 , ad_loss:  0.0012804884 , g_loss:  24.906414\n",
            "epoch:  132\n",
            "d_loss:  -24.470821 , ad_loss:  0.00032596034 , g_loss:  26.329502\n",
            "epoch:  133\n",
            "d_loss:  -24.590908 , ad_loss:  -0.0018979297 , g_loss:  25.799477\n",
            "epoch:  134\n",
            "d_loss:  -25.008974 , ad_loss:  0.023608396 , g_loss:  25.349207\n",
            "epoch:  135\n",
            "d_loss:  -24.186161 , ad_loss:  0.04022909 , g_loss:  25.062733\n",
            "epoch:  136\n",
            "d_loss:  -24.267033 , ad_loss:  0.0028599733 , g_loss:  24.747957\n",
            "epoch:  137\n",
            "d_loss:  -25.049625 , ad_loss:  -0.0023820284 , g_loss:  25.785393\n",
            "epoch:  138\n",
            "d_loss:  -25.3881 , ad_loss:  -0.0044556577 , g_loss:  26.071218\n",
            "epoch:  139\n",
            "d_loss:  -25.08123 , ad_loss:  -0.0046805185 , g_loss:  26.256575\n",
            "epoch:  140\n",
            "d_loss:  -26.495903 , ad_loss:  0.008413041 , g_loss:  24.663355\n",
            "epoch:  141\n",
            "d_loss:  -24.179958 , ad_loss:  0.005594389 , g_loss:  25.08457\n",
            "epoch:  142\n",
            "d_loss:  -24.088274 , ad_loss:  0.007058909 , g_loss:  26.108042\n",
            "epoch:  143\n",
            "d_loss:  -25.338848 , ad_loss:  -0.01373734 , g_loss:  24.87293\n",
            "epoch:  144\n",
            "d_loss:  -24.03312 , ad_loss:  0.013004368 , g_loss:  24.925484\n",
            "epoch:  145\n",
            "d_loss:  -24.818933 , ad_loss:  0.018631617 , g_loss:  25.847212\n",
            "epoch:  146\n",
            "d_loss:  -26.043453 , ad_loss:  -0.013080884 , g_loss:  26.104107\n",
            "epoch:  147\n",
            "d_loss:  -24.146423 , ad_loss:  -0.0023278743 , g_loss:  24.309978\n",
            "epoch:  148\n",
            "d_loss:  -23.92102 , ad_loss:  0.0059812036 , g_loss:  24.464884\n",
            "epoch:  149\n",
            "d_loss:  -25.796509 , ad_loss:  0.012345899 , g_loss:  25.357689\n",
            "epoch:  150\n",
            "d_loss:  -24.740065 , ad_loss:  -0.017426308 , g_loss:  25.682001\n",
            "epoch:  151\n",
            "d_loss:  -24.34483 , ad_loss:  0.038382 , g_loss:  24.76537\n",
            "epoch:  152\n",
            "d_loss:  -25.369137 , ad_loss:  0.004185731 , g_loss:  24.663282\n",
            "epoch:  153\n",
            "d_loss:  -25.842346 , ad_loss:  0.005262208 , g_loss:  25.457277\n",
            "epoch:  154\n",
            "d_loss:  -25.309704 , ad_loss:  -0.015953267 , g_loss:  25.515484\n",
            "epoch:  155\n",
            "d_loss:  -25.478575 , ad_loss:  -0.0031311836 , g_loss:  25.569715\n",
            "epoch:  156\n",
            "d_loss:  -24.71072 , ad_loss:  0.067997664 , g_loss:  25.057138\n",
            "epoch:  157\n",
            "d_loss:  -25.483006 , ad_loss:  0.023709588 , g_loss:  25.47076\n",
            "epoch:  158\n",
            "d_loss:  -24.43296 , ad_loss:  -0.0002942254 , g_loss:  24.61148\n",
            "epoch:  159\n",
            "d_loss:  -24.871065 , ad_loss:  0.0037057903 , g_loss:  25.517498\n",
            "epoch:  160\n",
            "d_loss:  -25.569637 , ad_loss:  -0.004657576 , g_loss:  25.786139\n",
            "epoch:  161\n",
            "d_loss:  -25.329634 , ad_loss:  -0.003923353 , g_loss:  25.100702\n",
            "epoch:  162\n",
            "d_loss:  -24.734299 , ad_loss:  -0.0017834343 , g_loss:  25.852264\n",
            "epoch:  163\n",
            "d_loss:  -24.401537 , ad_loss:  -0.015418227 , g_loss:  25.190271\n",
            "epoch:  164\n",
            "d_loss:  -25.181202 , ad_loss:  -0.0043325266 , g_loss:  25.552723\n",
            "epoch:  165\n",
            "d_loss:  -25.111319 , ad_loss:  -0.00804203 , g_loss:  25.841244\n",
            "epoch:  166\n",
            "d_loss:  -26.114155 , ad_loss:  0.00095529156 , g_loss:  25.325201\n",
            "epoch:  167\n",
            "d_loss:  -24.179909 , ad_loss:  -0.0006892132 , g_loss:  26.26564\n",
            "epoch:  168\n",
            "d_loss:  -24.216179 , ad_loss:  -0.012612136 , g_loss:  24.889034\n",
            "epoch:  169\n",
            "d_loss:  -25.907349 , ad_loss:  0.003728122 , g_loss:  26.388536\n",
            "epoch:  170\n",
            "d_loss:  -23.311462 , ad_loss:  -0.009265643 , g_loss:  25.599585\n",
            "epoch:  171\n",
            "d_loss:  -24.460064 , ad_loss:  -0.0040561734 , g_loss:  25.683178\n",
            "epoch:  172\n",
            "d_loss:  -25.281204 , ad_loss:  -0.007760447 , g_loss:  25.328112\n",
            "epoch:  173\n",
            "d_loss:  -24.951952 , ad_loss:  -0.010283119 , g_loss:  26.375856\n",
            "epoch:  174\n",
            "d_loss:  -24.736937 , ad_loss:  -0.008366322 , g_loss:  24.469831\n",
            "epoch:  175\n",
            "d_loss:  -24.377495 , ad_loss:  -0.01352099 , g_loss:  25.19065\n",
            "epoch:  176\n",
            "d_loss:  -25.292416 , ad_loss:  0.00026713364 , g_loss:  25.964321\n",
            "epoch:  177\n",
            "d_loss:  -25.557014 , ad_loss:  -0.006342538 , g_loss:  26.137888\n",
            "epoch:  178\n",
            "d_loss:  -25.516794 , ad_loss:  0.0036822201 , g_loss:  25.290154\n",
            "epoch:  179\n",
            "d_loss:  -23.230473 , ad_loss:  -0.0029043427 , g_loss:  24.596012\n",
            "epoch:  180\n",
            "d_loss:  -25.818106 , ad_loss:  -0.0072227158 , g_loss:  25.613045\n",
            "epoch:  181\n",
            "d_loss:  -24.666004 , ad_loss:  0.0033615448 , g_loss:  25.707664\n",
            "epoch:  182\n",
            "d_loss:  -25.017801 , ad_loss:  0.080202304 , g_loss:  24.432037\n",
            "epoch:  183\n",
            "d_loss:  -24.59808 , ad_loss:  0.0012272004 , g_loss:  25.33697\n",
            "epoch:  184\n",
            "d_loss:  -25.149757 , ad_loss:  0.009026587 , g_loss:  25.977129\n",
            "epoch:  185\n",
            "d_loss:  -25.99953 , ad_loss:  -0.0073890076 , g_loss:  26.317123\n",
            "epoch:  186\n",
            "d_loss:  -24.175213 , ad_loss:  -0.007910939 , g_loss:  26.07487\n",
            "epoch:  187\n",
            "d_loss:  -25.168062 , ad_loss:  0.0005626342 , g_loss:  25.289324\n",
            "epoch:  188\n",
            "d_loss:  -25.029404 , ad_loss:  -0.0021469616 , g_loss:  25.261864\n",
            "epoch:  189\n",
            "d_loss:  -25.014395 , ad_loss:  -0.012612791 , g_loss:  26.013775\n",
            "epoch:  190\n",
            "d_loss:  -25.797237 , ad_loss:  0.003633243 , g_loss:  25.79363\n",
            "epoch:  191\n",
            "d_loss:  -24.185234 , ad_loss:  -0.023366159 , g_loss:  25.247532\n",
            "epoch:  192\n",
            "d_loss:  -25.049337 , ad_loss:  0.003869639 , g_loss:  25.22046\n",
            "epoch:  193\n",
            "d_loss:  -23.811535 , ad_loss:  -0.019288156 , g_loss:  24.292007\n",
            "epoch:  194\n",
            "d_loss:  -24.430492 , ad_loss:  -0.0021988726 , g_loss:  25.24116\n",
            "epoch:  195\n",
            "d_loss:  -26.13266 , ad_loss:  0.0005064463 , g_loss:  26.145887\n",
            "epoch:  196\n",
            "d_loss:  -24.831703 , ad_loss:  -0.005230936 , g_loss:  24.189247\n",
            "epoch:  197\n",
            "d_loss:  -24.472637 , ad_loss:  0.0048301555 , g_loss:  23.962257\n",
            "epoch:  198\n",
            "d_loss:  -25.289364 , ad_loss:  0.0021369816 , g_loss:  24.430836\n",
            "epoch:  199\n",
            "d_loss:  -25.0389 , ad_loss:  -0.0071226493 , g_loss:  24.207518\n",
            "----FINISHED TRAINING-----\n",
            "----START GENERATING------\n",
            "22\n",
            "----SAMPLE FROM-----\n",
            "(1347, 130, 47)\n",
            "(1347, 35)\n",
            "(1347, 130)\n",
            "(1347,)\n",
            "----RENORMALIZATION-----\n",
            "(1347, 130, 47)\n",
            "(1347, 1)\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV-QV7IEs9-R"
      },
      "source": [
        "Remember to download the generated file \"generated_data_train.npz\" by selecting the 3 vertical dots next to the file name and selecting download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsPj7jnLMkta"
      },
      "source": [
        "Remember to also download the checkpoint folders so that they can be loaded during the next training session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "852DhpMpMipI",
        "outputId": "e238d6bc-b982-4714-ae2c-49464b842cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# zip the checkpoint folders\n",
        "!zip -r tf_ckpts_ad.zip tf_ckpts_ad\n",
        "!zip -r tf_ckpts_d.zip tf_ckpts_d\n",
        "!zip -r tf_ckpts_g.zip tf_ckpts_g"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: tf_ckpts_ad/ (stored 0%)\n",
            "  adding: tf_ckpts_ad/ckpt-999.index (deflated 68%)\n",
            "  adding: tf_ckpts_ad/ckpt-998.index (deflated 68%)\n",
            "  adding: tf_ckpts_ad/checkpoint (deflated 63%)\n",
            "  adding: tf_ckpts_ad/ckpt-1000.index (deflated 68%)\n",
            "  adding: tf_ckpts_ad/ckpt-1000.data-00000-of-00001 (deflated 25%)\n",
            "  adding: tf_ckpts_ad/ckpt-998.data-00000-of-00001 (deflated 25%)\n",
            "  adding: tf_ckpts_ad/ckpt-999.data-00000-of-00001 (deflated 25%)\n",
            "  adding: tf_ckpts_d/ (stored 0%)\n",
            "  adding: tf_ckpts_d/ckpt-999.index (deflated 68%)\n",
            "  adding: tf_ckpts_d/ckpt-998.index (deflated 68%)\n",
            "  adding: tf_ckpts_d/checkpoint (deflated 63%)\n",
            "  adding: tf_ckpts_d/ckpt-1000.index (deflated 68%)\n",
            "  adding: tf_ckpts_d/ckpt-1000.data-00000-of-00001 (deflated 30%)\n",
            "  adding: tf_ckpts_d/ckpt-998.data-00000-of-00001 (deflated 30%)\n",
            "  adding: tf_ckpts_d/ckpt-999.data-00000-of-00001 (deflated 30%)\n",
            "  adding: tf_ckpts_g/ (stored 0%)\n",
            "  adding: tf_ckpts_g/ckpt-999.index (deflated 82%)\n",
            "  adding: tf_ckpts_g/ckpt-998.index (deflated 82%)\n",
            "  adding: tf_ckpts_g/checkpoint (deflated 63%)\n",
            "  adding: tf_ckpts_g/ckpt-1000.index (deflated 82%)\n",
            "  adding: tf_ckpts_g/ckpt-1000.data-00000-of-00001 (deflated 39%)\n",
            "  adding: tf_ckpts_g/ckpt-998.data-00000-of-00001 (deflated 39%)\n",
            "  adding: tf_ckpts_g/ckpt-999.data-00000-of-00001 (deflated 39%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xa6MO7COG1V",
        "outputId": "75d80754-a9de-4856-bed4-c2f3adc72c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# download zip files (***might only work with google chrome, if it doesn't work, manually download zip by pressing the 3 vertical dots)\n",
        "from google.colab import files\n",
        "files.download(\"tf_ckpts_ad.zip\")\n",
        "files.download(\"tf_ckpts_d.zip\")\n",
        "files.download(\"tf_ckpts_g.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_54deaf6b-e59c-45ae-a64b-41783f33c06b\", \"tf_ckpts_ad.zip\", 3475560)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_617f8910-e936-4f2c-89fa-16e2770bc81c\", \"tf_ckpts_d.zip\", 35242016)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7b83f9ca-dd9f-4892-8db2-c3476074e568\", \"tf_ckpts_g.zip\", 24909835)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnvzN0lTtSfk",
        "outputId": "8ca75b0b-e6ca-4964-f545-d76d14956ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "files.download(\"generated_data_train.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_bbe69f78-654b-4c72-bc5d-16390fc60e97\", \"generated_data_train.npz\", 33627304)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNN2I923OqGI"
      },
      "source": [
        "Take a note of how the file directory looks like with the checkpoint folders and make sure that it looks the same the next you run the training\n",
        "\n",
        "-data  \n",
        "  >--data_attribute_output.pkl  \n",
        "  --data_feature_output.pkl  \n",
        "  --data_train.npz  \n",
        "\n",
        "-doppelganger.py  \n",
        "-load_data.py  \n",
        "-network.py  \n",
        "-networkGenerator.py  \n",
        "-output.py  \n",
        "-util.py  \n",
        "-tf_ckpts_ad  (folder)  \n",
        "-tf_ckpts_d  (folder)  \n",
        "-tf_ckpts_g  (folder)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSG6WBTWtG1Y"
      },
      "source": [
        "####How to terminate runtime\n",
        "\n",
        "1. Go to the top right corner with RAM and Disk and press the downwards arrow\n",
        "\n",
        "2. Select Manage Sessions\n",
        "\n",
        "3. Select Terminate\n",
        "\n",
        "**Note that all uploaded and generated files will be deleted when you terminate runtime**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Mf6pIRskc6"
      },
      "source": [
        "# if you need to delete any folders\n",
        "\n",
        "#!rm -rf <replace_with name_of_folder>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtV2Uiv_RmZa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}